{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (10 points) Change the variable my_path to reflect a directory on your laptop where you will store the crawled websites and enter in ‘qmss columbia’ as the variable called ‘the_query’, then run the program (with my_top.py open run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done. Will upload the changed my_top.py file - called my_top_q1.py. New code for my_top.py pasted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.qmss.columbia.edu/\n",
      "https://gsas.columbia.edu/degree-programs/ma-programs/quantitative-methods-social-sciences\n",
      "http://iserp.columbia.edu/hiring-payroll/qmss-ra-program\n",
      "https://medium.com/%40RobinCRLee/review-on-columbia-qmss-ma-program-d22c0db2f0d7\n",
      "https://twitter.com/qmss_columbia%3Flang%3Den\n",
      "https://www.facebook.com/Quantitative-Methods-in-Social-Sciences-QMSS-Columbia-University-147741968642064/\n",
      "https://www.goodreads.com/group/show/80365-qmss-at-columbia-university\n",
      "https://economics.rice.edu/undergraduate-program/resources/student-opportunities/qmss-columbia-university\n",
      "http://qmss.squarespace.com/columbia-bama/\n",
      "https://asintunado.wordpress.com/2016/10/02/m-a-quantitative-methods-in-the-social-sciences-at-columbia-university-things-you-should-know/\n",
      "https://twitter.com/qmss_columbia/status/910130204743528448\n",
      "https://www.coursicle.com/columbia/courses/QMSS/G5999/\n",
      "https://publish.illinois.edu/statadvising/2013/10/16/masters-opportunity-columbia-university-quantitative-methods-in-the-social-sciences/\n",
      "https://forum.thegradcafe.com/topic/77005-nyu-ms-data-science-vs-columbia-ma-qmss/\n",
      "https://github.com/Columbia-University-QMSS\n",
      "https://www.urch.com/forums/phd-economics/111934-quantitative-methods-social-sciences-columbia-other-ma-programs.html\n",
      "https://www.idealist.org/en/nonprofit/d919b5c9c93b4d14801689c7b99c7d11-columbia-university-quantitative-methods-in-the-social-sciences-ma-program-new-york\n",
      "http://umdecon.blogspot.com/2012/10/colubmia-university-master-of-arts-in.html\n",
      "https://uwecon.wordpress.com/2019/01/16/columbias-qmss-ma-program/\n",
      "https://listserv.wustl.edu/scripts/wa.exe%3FA2%3Dind1806A%26L%3DPOLMETH%26P%3D4196\n",
      "https://rdrr.io/github/jgabry/QMSS_package/man/QMSS.html\n",
      "https://dataverse.harvard.edu/dataverse/nh2376_qmss_thesis\n",
      "http://greatfabrik.com/index.php/qmss-columbia-thesis\n",
      "https://www.meetup.com/nyhackr/messages/boards/thread/49058120\n",
      "http://oakland.edu/Assets/upload/docs/AIS/Masters-Directory/91_COLUMBIA-UNIVERSITY%25C2%25A0-%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0-%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0-%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0-%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0%25C2%25A0.pdf\n",
      "http://greentree-sa.com/us2u/columbia-qmss-tuition.html\n",
      "http://minnies.itvenza.com/qmss-columbia-thesis\n",
      "https://barnard.edu/4plus1-pathway-quantitative-masters-social-sciences\n",
      "https://www.poormagazine.org/node/1774\n",
      "https://talk.collegeconfidential.com/graduate-school/1675544-columbia-qmss-ma-program.html\n",
      "https://www.mastersportal.com/studies/74546/quantitative-methods-in-the-social-sciences.html\n",
      "https://maliha-tariq.com/2018/04/02/sometimes-i-write-things/\n",
      "https://www.poliscirumors.com/topic/chicago-macss-vs-columbia-qmss-as-phd-prep\n",
      "http://websites.milonic.com/qmss.columbia.edu\n",
      "https://www.quora.com/Should-I-apply-to-Columbia-Universitys-MA-in-economics-or-MA-in-QMSS-and-concentrate-in-economics\n",
      "http://clubedofrancisco.com.br/g7esz/qmss-2019.html\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct  4 07:35:36 2019\n",
    "\n",
    "@author: pathouli\n",
    "\"\"\"\n",
    "\n",
    "from crawler import crawler\n",
    "\n",
    "my_path = 'C:/Users/Timothy/Google Drive/TC Stuff/Analytics/GR 5067 - Natural Language Processing in Social Sciences/HW2/files_q1'\n",
    "the_query = 'qmss columbia'\n",
    "num_docs = 50\n",
    "\n",
    "my_func = crawler()\n",
    "\n",
    "my_func.write_crawl_results(my_path, the_query, num_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Perform the same search using googles search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Perform a quick comparison between the google crawl results and the outputted text files. What are some observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Google Search result URLs are mostly identical to google crawl results\n",
    "* Some results are excluded - 35 text files were written on my computer, despite the function call for 50 docs to return.\n",
    "* Some sites block access to the crawler - 5th (index 4) result from the crawler is \"You can search Twitter using the search box below or return to the homepage\". The blurb in the google search preview says \"The latest Tweets from QMSS at Columbia (@qmss_columbia). Quantitative Methods in the Social Sciences MA: Interdisciplinary research program for a ...\" \n",
    "* Sometimes the google preview filters out more things than the crawler. The 8th result (index 7) from Google web shows \"MA in Quantitative Methods in the Social Sciences. Quantitative Methods in the Social Sciences (QMSS) is an innovative, flexible, interdisciplinary social science ...\", omitting a disclaimer at the top of the page that was included in the crawler \"The student opportunity listed below has been submitted to the Rice Economics Department and is posted for informational purposes only Inclusion here does not imply endorsement by the department and students should do their own due diligence in investigating this opportunity Please report any suspect or expired opportunities to econ rice edu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (35 points) Refactor the file called my_top.py to loop through 4 topics of your choice; do not run the code yet, move to step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done. Will upload the final my_top.py file - called my_top_q2.py. New code for my_top.py pasted in cell below:\n",
    "\n",
    "Searches taken from my google search history: \n",
    "* sceptile\n",
    "* virizion\n",
    "* power law\n",
    "* lists in r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bulbapedia.bulbagarden.net/wiki/Sceptile_(Pok%25C3%25A9mon)\n",
      "https://pokemondb.net/pokedex/sceptile\n",
      "https://www.pokemon.com/us/pokedex/sceptile\n",
      "https://pokemongo.gamepress.gg/pokemon/254\n",
      "https://veekun.com/dex/pokemon/sceptile%3Fform%3Dmega\n",
      "https://bulbapedia.bulbagarden.net/wiki/Virizion_(Pok%25C3%25A9mon)\n",
      "https://pokemondb.net/pokedex/virizion\n",
      "https://www.pokemon.com/us/pokedex/virizion\n",
      "https://veekun.com/dex/pokemon/virizion\n",
      "https://necsi.edu/power-law\n",
      "http://www.di.fc.ul.pt/~jpn/r/powerlaw/powerlaw.html\n",
      "https://www.tutorialspoint.com/r/r_lists.htm\n",
      "http://www.r-tutor.com/r-introduction/list\n",
      "https://data-flair.training/blogs/r-list-tutorial/\n",
      "https://www.datamentor.io/r-programming/list/\n",
      "https://www.datacamp.com/community/tutorials/creating-lists-r\n",
      "https://www.r-bloggers.com/how-to-use-lists-in-r/\n",
      "https://www.rdocumentation.org/packages/base/versions/3.6.1/topics/list\n",
      "http://uc-r.github.io/lists\n",
      "https://faculty.nps.edu/sebuttre/home/R/lists.html\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct  4 07:35:36 2019\n",
    "\n",
    "@author: pathouli\n",
    "\"\"\"\n",
    "\n",
    "from crawler import crawler\n",
    "\n",
    "my_path = 'C:/Users/Timothy/Google Drive/TC Stuff/Analytics/GR 5067 - Natural Language Processing in Social Sciences/HW2/files_q1'\n",
    "\n",
    "searches = [\"sceptile\", \"virizion\", \"power law\", \"lists in r\"]\n",
    "\n",
    "for search in searches:\n",
    "\n",
    "    the_query = search\n",
    "    num_docs = 10\n",
    "    \n",
    "    my_func = crawler()\n",
    "    \n",
    "    my_func.write_crawl_results(my_path, the_query, num_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\n",
    "(55 points) Refactor the file called crawler.py to not write to text files, but rather append a pandas dataframe called ‘the_data’, accessible on my_top.py, that contains three columns:\n",
    "\n",
    "* 'body_basic' - basic removal of special characters; already coded for you\n",
    "* 'body_stem' - perform stemming on body_basic and write resultant to this column\n",
    "* 'label' - what query the body relates to; if more than one word exist in the query, concatenate all words together with a ‘_’ between them all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I copied the crawler.py code in the cell below.\n",
    "The cell after it contains the corresponding my_top.py code that calls the crawler and prints the data frame. Some amendments have been made.\n",
    "\n",
    "The modified files are uploaded and called\n",
    "* crawler1.py\n",
    "* my_top_q3.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### crawler1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Oct  5 13:05:36 2019\n",
    "\n",
    "@author: pathouli\n",
    "\"\"\"\n",
    "\n",
    "class crawler1(object):\n",
    "\n",
    "    def my_scraper(self, tmp_url_in):\n",
    "        from bs4 import BeautifulSoup\n",
    "        import requests\n",
    "        import re\n",
    "        #url = 'http://www.qmss.columbia.edu/faculty-and-staff'\n",
    "        tmp_text = ''\n",
    "        try:\n",
    "            content = requests.get(tmp_url_in)\n",
    "            soup = BeautifulSoup(content.text, 'html.parser')\n",
    "    \n",
    "            tmp_text = soup.findAll('p') \n",
    "    \n",
    "            tmp_text = [word.text for word in tmp_text]\n",
    "            tmp_text = ' '.join(tmp_text)\n",
    "            tmp_text = re.sub('\\W+', ' ', re.sub('xa0', ' ', tmp_text))\n",
    "            #tmp_text = re.sub('\\W+', ' ', tmp_text)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        return tmp_text\n",
    "    \n",
    "    def fetch_urls(self, query, cnt):\n",
    "        #now lets use the following function that returns\n",
    "        #URLs from an arbitrary regex crawl form google\n",
    "    \n",
    "        #pip install pyyaml ua-parser user-agents fake-useragent\n",
    "        import requests\n",
    "        from fake_useragent import UserAgent\n",
    "        from bs4 import BeautifulSoup\n",
    "        import re \n",
    "        ua = UserAgent()\n",
    "    \n",
    "        #query = 'fishing'\n",
    "    \n",
    "        google_url = \"https://www.google.com/search?q=\" + query + \"&num=\" + str(cnt)\n",
    "        response = requests.get(google_url, {\"User-Agent\": ua.random})\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "        result_div = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "    \n",
    "        links = []\n",
    "        titles = []\n",
    "        descriptions = []\n",
    "        for r in result_div:\n",
    "            # Checks if each element is present, else, raise exception\n",
    "            try:\n",
    "                link = r.find('a', href = True)\n",
    "                title = r.find('div', attrs={'class':'vvjwJb'}).get_text()\n",
    "                description = r.find('div', attrs={'class':'s3v9rd'}).get_text()\n",
    "    \n",
    "                # Check to make sure everything is present before appending\n",
    "                if link != '' and title != '' and description != '': \n",
    "                    links.append(link['href'])\n",
    "                    titles.append(title)\n",
    "                    descriptions.append(description)\n",
    "            # Next loop if one element is not present\n",
    "            except:\n",
    "                continue  \n",
    "    \n",
    "        to_remove = []\n",
    "        clean_links = []\n",
    "        for i, l in enumerate(links):\n",
    "            clean = re.search('\\/url\\?q\\=(.*)\\&sa',l)\n",
    "    \n",
    "            # Anything that doesn't fit the above pattern will be removed\n",
    "            if clean is None:\n",
    "                to_remove.append(i)\n",
    "                continue\n",
    "            clean_links.append(clean.group(1))\n",
    "    \n",
    "        # Remove the corresponding titles & descriptions\n",
    "        for x in to_remove:\n",
    "            del titles[x]\n",
    "            del descriptions[x]\n",
    "            \n",
    "        return clean_links\n",
    " \n",
    "    def write_crawl_results(self, my_query, the_cnt_in):\n",
    "        \n",
    "        #Import needed libraries\n",
    "        import pandas as pd\n",
    "        from nltk.stem import PorterStemmer\n",
    "        import re\n",
    "        \n",
    "        #Create empty data frame\n",
    "        the_data = pd.DataFrame()\n",
    "        #Create PorterStemmer object for stemming\n",
    "        my_stemmer = PorterStemmer()\n",
    "        #Label to include in data frame column\n",
    "        the_label = re.sub('[\\s]+', '_', my_query)\n",
    "        \n",
    "        #Call fetch_urls to get our list of URLs\n",
    "        the_urls_list = self.fetch_urls(my_query, the_cnt_in)\n",
    "        \n",
    "        #For each URL in the list of URLs, get the text, process, and make an entry in our data frame\n",
    "        for link in the_urls_list:\n",
    "            #Get the cleaned text by calling my_scraper\n",
    "            body_basic = self.my_scraper(link)\n",
    "            \n",
    "            #If statement to further process only websites with actual text.\n",
    "            if len(body_basic) != 0:\n",
    "                try:\n",
    "                    #Use our PorterStemmer object to stem body_basic, and store the result in body_stem\n",
    "                    body_stem = [my_stemmer.stem(one_word) for one_word in body_basic.split()]\n",
    "                    #Create the dictionary to enter into our data frame\n",
    "                    entry = {'label': the_label,\n",
    "                             'URL': link,\n",
    "                            'body_basic': body_basic,\n",
    "                            'body_stem': body_stem}\n",
    "                    #Enter our dictionary entry into the data frame\n",
    "                    the_data = the_data.append(entry, ignore_index = True)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "        \n",
    "        return(the_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my_top_q3.py\n",
    "\n",
    "my_top_q3.py is below. The code has been changed to assume a list of searches.\n",
    "Each data frame resulting from each search is stored into a list called results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 URL  \\\n",
      "0  https://bulbapedia.bulbagarden.net/wiki/Scepti...   \n",
      "1             https://pokemondb.net/pokedex/sceptile   \n",
      "2        https://www.pokemon.com/us/pokedex/sceptile   \n",
      "3       https://www.serebii.net/pokedex-xy/254.shtml   \n",
      "4           https://pokemon.fandom.com/wiki/Sceptile   \n",
      "5         https://pokemongo.gamepress.gg/pokemon/254   \n",
      "6  https://veekun.com/dex/pokemon/sceptile%3Fform...   \n",
      "\n",
      "                                          body_basic  \\\n",
      "0  The requested page title contains invalid char...   \n",
      "1  Sceptile is a Grass type Pokémon introduced in...   \n",
      "2   Sceptile has seeds growing on its back They a...   \n",
      "3   Picture Name Other Names No Gender Ratio Type...   \n",
      "4   Sceptile ジュカイン Jukain Generation Generation I...   \n",
      "5  Sceptile was already among the top Grass types...   \n",
      "6  Log in or register Pokédex Oh I was holding it...   \n",
      "\n",
      "                                           body_stem     label  \n",
      "0  [the, request, page, titl, contain, invalid, c...  sceptile  \n",
      "1  [sceptil, is, a, grass, type, pokémon, introdu...  sceptile  \n",
      "2  [sceptil, ha, seed, grow, on, it, back, they, ...  sceptile  \n",
      "3  [pictur, name, other, name, No, gender, ratio,...  sceptile  \n",
      "4  [sceptil, ジュカイン, jukain, gener, gener, iii, ev...  sceptile  \n",
      "5  [sceptil, wa, alreadi, among, the, top, grass,...  sceptile  \n",
      "6  [log, in, or, regist, pokédex, Oh, I, wa, hold...  sceptile  \n",
      "                                                 URL  \\\n",
      "0  https://bulbapedia.bulbagarden.net/wiki/Virizi...   \n",
      "1             https://pokemondb.net/pokedex/virizion   \n",
      "2        https://www.pokemon.com/us/pokedex/virizion   \n",
      "3       https://www.serebii.net/pokedex-xy/640.shtml   \n",
      "4           https://pokemon.fandom.com/wiki/Virizion   \n",
      "5            https://veekun.com/dex/pokemon/virizion   \n",
      "6             https://pokemon.gamepedia.com/Virizion   \n",
      "\n",
      "                                          body_basic  \\\n",
      "0  The requested page title contains invalid char...   \n",
      "1  Virizion is a Grass Fighting type Pokémon intr...   \n",
      "2   Legends say this Pokémon confounded opponents...   \n",
      "3   Picture Name Other Names No Gender Ratio Type...   \n",
      "4   200 0 kg 2 0 m Virizion Japanese ビリジオン Biriji...   \n",
      "5  Log in or register Pokédex Virizion Grassland ...   \n",
      "6   Category Green Pokémon Virizion Japanese ビリジオ...   \n",
      "\n",
      "                                           body_stem     label  \n",
      "0  [the, request, page, titl, contain, invalid, c...  virizion  \n",
      "1  [virizion, is, a, grass, fight, type, pokémon,...  virizion  \n",
      "2  [legend, say, thi, pokémon, confound, oppon, w...  virizion  \n",
      "3  [pictur, name, other, name, No, gender, ratio,...  virizion  \n",
      "4  [200, 0, kg, 2, 0, m, virizion, japanes, ビリジオン...  virizion  \n",
      "5  [log, in, or, regist, pokédex, virizion, grass...  virizion  \n",
      "6  [categori, green, pokémon, virizion, japanes, ...  virizion  \n",
      "                                                 URL  \\\n",
      "0            https://en.wikipedia.org/wiki/Power_law   \n",
      "1  https://www.statisticshowto.datasciencecentral...   \n",
      "2                https://fs.blog/2017/11/power-laws/   \n",
      "3  https://medium.com/%40michaeltauberg/power-law...   \n",
      "4                        https://necsi.edu/power-law   \n",
      "5  http://www.di.fc.ul.pt/~jpn/r/powerlaw/powerla...   \n",
      "\n",
      "                                          body_basic  \\\n",
      "0  In statistics a power law is a functional rela...   \n",
      "1   Statistics Definitions Power Law The power la...   \n",
      "2   Albert Allen Bartlett Consider a person who b...   \n",
      "3   No one man should have all that power Kanye W...   \n",
      "4  A power law is a relationship in which a relat...   \n",
      "5  Refs Zipf Power laws and Pareto a ranking tuto...   \n",
      "\n",
      "                                           body_stem      label  \n",
      "0  [In, statist, a, power, law, is, a, function, ...  power_law  \n",
      "1  [statist, definit, power, law, the, power, law...  power_law  \n",
      "2  [albert, allen, bartlett, consid, a, person, w...  power_law  \n",
      "3  [No, one, man, should, have, all, that, power,...  power_law  \n",
      "4  [A, power, law, is, a, relationship, in, which...  power_law  \n",
      "5  [ref, zipf, power, law, and, pareto, a, rank, ...  power_law  \n",
      "                                                 URL  \\\n",
      "0       https://www.tutorialspoint.com/r/r_lists.htm   \n",
      "1         http://www.r-tutor.com/r-introduction/list   \n",
      "2  https://data-flair.training/blogs/r-list-tutor...   \n",
      "3      https://www.datamentor.io/r-programming/list/   \n",
      "4  https://www.datacamp.com/community/tutorials/c...   \n",
      "5  https://www.r-bloggers.com/how-to-use-lists-in-r/   \n",
      "6  https://www.rdocumentation.org/packages/base/v...   \n",
      "7                        http://uc-r.github.io/lists   \n",
      "8  https://faculty.nps.edu/sebuttre/home/R/lists....   \n",
      "\n",
      "                                          body_basic  \\\n",
      "0  Lists are the R objects which contain elements...   \n",
      "1  An appropriate representation of the requested...   \n",
      "2  DataFlair DataFlair Learn Today Lead Tomorrow ...   \n",
      "3  In this article you will learn to work with li...   \n",
      "4  If you want to take our free Intro to R course...   \n",
      "5   This article was first published on R for Pub...   \n",
      "6  Percentile Functions to construct coerce and c...   \n",
      "7   Follow me on twitter bradleyboehmke A list is...   \n",
      "8   Lists A list is an R structure that may conta...   \n",
      "\n",
      "                                           body_stem       label  \n",
      "0  [list, are, the, R, object, which, contain, el...  lists_in_r  \n",
      "1  [An, appropri, represent, of, the, request, re...  lists_in_r  \n",
      "2  [dataflair, dataflair, learn, today, lead, tom...  lists_in_r  \n",
      "3  [In, thi, articl, you, will, learn, to, work, ...  lists_in_r  \n",
      "4  [If, you, want, to, take, our, free, intro, to...  lists_in_r  \n",
      "5  [thi, articl, wa, first, publish, on, R, for, ...  lists_in_r  \n",
      "6  [percentil, function, to, construct, coerc, an...  lists_in_r  \n",
      "7  [follow, me, on, twitter, bradleyboehmk, A, li...  lists_in_r  \n",
      "8  [list, A, list, is, an, R, structur, that, may...  lists_in_r  \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct  4 07:35:36 2019\n",
    "\n",
    "@author: pathouli\n",
    "\"\"\"\n",
    "\n",
    "from crawler1 import crawler1\n",
    "\n",
    "searches = [\"sceptile\", \"virizion\", \"power law\", \"lists in r\"]\n",
    "results = []\n",
    "\n",
    "for search in searches: \n",
    "    the_query = search\n",
    "    num_docs = 10\n",
    "\n",
    "    my_func = crawler1()\n",
    "\n",
    "    search_results = my_func.write_crawl_results(the_query, num_docs)\n",
    "    print(search_results)\n",
    "    results.append(search_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
